{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mnist dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, drop_last=True)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_labels(labels, n_classes):\n",
    "    return F.one_hot(labels, n_classes).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "labels = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0])\n",
    "one_hot_labels = get_one_hot_labels(labels, 10)\n",
    "print(one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 7, 3, 6, 9, 0, 0, 8, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.randint(0, 10, (10,))\n",
    "print(labels)\n",
    "get_one_hot_labels(labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_vectors(x, y):\n",
    "    return torch.cat((x.float(), y.float()), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(10, 100)\n",
    "Y = get_one_hot_labels(labels, 10)\n",
    "combined = combine_vectors(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 110])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 110])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class cGAN_Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_classes):\n",
    "        super(cGAN_Generator, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_classes = n_classes\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(self.input_size + self.n_classes, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size * 2, self.hidden_size * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size * 4, self.output_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x, y):\n",
    "        combined = combine_vectors(x, y)\n",
    "        return self.seq(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 100\n",
    "hidden_size = 128\n",
    "output_size = 784\n",
    "n_classes = 10\n",
    "generator = cGAN_Generator(input_size, hidden_size, output_size, n_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "noise = torch.randn(batch_size, input_size).to(device)\n",
    "labels = torch.randint(0, n_classes, (batch_size,)).to(device)\n",
    "one_hot_labels = get_one_hot_labels(labels, n_classes).to(device)\n",
    "gen_out = generator(noise, one_hot_labels)\n",
    "print(gen_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class cGAN_Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_classes):\n",
    "        super(cGAN_Discriminator, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_classes = n_classes\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(self.input_size + self.n_classes, self.hidden_size * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.hidden_size * 4, self.hidden_size * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.hidden_size * 2, self.hidden_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.hidden_size, self.output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, y):\n",
    "        combined = combine_vectors(x, y)\n",
    "        return self.seq(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "n_classes = 10\n",
    "discriminator = cGAN_Discriminator(input_size, hidden_size, output_size, n_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "#feed the generator output to the discriminator\n",
    "disc_out = discriminator(gen_out, one_hot_labels)\n",
    "print(disc_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "lr = 0.0002\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Step [200/937], d_loss: 0.9060, g_loss: 1.3766, D(x): 0.67, D(G(z)): 0.33\n",
      "Epoch [0/100], Step [400/937], d_loss: 1.1862, g_loss: 1.1108, D(x): 0.59, D(G(z)): 0.42\n",
      "Epoch [0/100], Step [600/937], d_loss: 0.9657, g_loss: 1.2752, D(x): 0.61, D(G(z)): 0.27\n",
      "Epoch [0/100], Step [800/937], d_loss: 1.1038, g_loss: 1.2280, D(x): 0.68, D(G(z)): 0.44\n",
      "Epoch [1/100], Step [200/937], d_loss: 0.9696, g_loss: 1.3386, D(x): 0.64, D(G(z)): 0.33\n",
      "Epoch [1/100], Step [400/937], d_loss: 1.0772, g_loss: 1.1339, D(x): 0.68, D(G(z)): 0.42\n",
      "Epoch [1/100], Step [600/937], d_loss: 1.1009, g_loss: 1.0623, D(x): 0.62, D(G(z)): 0.41\n",
      "Epoch [1/100], Step [800/937], d_loss: 1.0500, g_loss: 1.3519, D(x): 0.65, D(G(z)): 0.35\n",
      "Epoch [2/100], Step [200/937], d_loss: 1.2337, g_loss: 1.1160, D(x): 0.58, D(G(z)): 0.40\n",
      "Epoch [2/100], Step [400/937], d_loss: 1.0625, g_loss: 1.1846, D(x): 0.59, D(G(z)): 0.35\n",
      "Epoch [2/100], Step [600/937], d_loss: 1.1738, g_loss: 1.0412, D(x): 0.59, D(G(z)): 0.40\n",
      "Epoch [2/100], Step [800/937], d_loss: 1.0926, g_loss: 0.9588, D(x): 0.63, D(G(z)): 0.38\n",
      "Epoch [3/100], Step [200/937], d_loss: 1.1261, g_loss: 1.1105, D(x): 0.62, D(G(z)): 0.42\n",
      "Epoch [3/100], Step [400/937], d_loss: 1.1637, g_loss: 1.3559, D(x): 0.62, D(G(z)): 0.42\n",
      "Epoch [3/100], Step [600/937], d_loss: 1.2629, g_loss: 0.9706, D(x): 0.57, D(G(z)): 0.42\n",
      "Epoch [3/100], Step [800/937], d_loss: 1.1382, g_loss: 1.5930, D(x): 0.56, D(G(z)): 0.29\n",
      "Epoch [4/100], Step [200/937], d_loss: 1.2287, g_loss: 0.9111, D(x): 0.61, D(G(z)): 0.43\n",
      "Epoch [4/100], Step [400/937], d_loss: 1.1798, g_loss: 1.4931, D(x): 0.61, D(G(z)): 0.38\n",
      "Epoch [4/100], Step [600/937], d_loss: 1.0852, g_loss: 1.0519, D(x): 0.62, D(G(z)): 0.38\n",
      "Epoch [4/100], Step [800/937], d_loss: 1.0350, g_loss: 1.3713, D(x): 0.63, D(G(z)): 0.36\n",
      "Epoch [5/100], Step [200/937], d_loss: 1.1111, g_loss: 1.3103, D(x): 0.65, D(G(z)): 0.40\n",
      "Epoch [5/100], Step [400/937], d_loss: 1.0301, g_loss: 1.2536, D(x): 0.64, D(G(z)): 0.36\n",
      "Epoch [5/100], Step [600/937], d_loss: 1.0771, g_loss: 1.0939, D(x): 0.63, D(G(z)): 0.39\n",
      "Epoch [5/100], Step [800/937], d_loss: 1.2623, g_loss: 1.0331, D(x): 0.59, D(G(z)): 0.42\n",
      "Epoch [6/100], Step [200/937], d_loss: 1.0440, g_loss: 1.1755, D(x): 0.62, D(G(z)): 0.34\n",
      "Epoch [6/100], Step [400/937], d_loss: 0.8599, g_loss: 1.3531, D(x): 0.67, D(G(z)): 0.27\n",
      "Epoch [6/100], Step [600/937], d_loss: 1.2378, g_loss: 0.9696, D(x): 0.61, D(G(z)): 0.45\n",
      "Epoch [6/100], Step [800/937], d_loss: 1.0831, g_loss: 1.3964, D(x): 0.59, D(G(z)): 0.32\n",
      "Epoch [7/100], Step [200/937], d_loss: 1.1478, g_loss: 1.0853, D(x): 0.63, D(G(z)): 0.42\n",
      "Epoch [7/100], Step [400/937], d_loss: 1.0296, g_loss: 1.2275, D(x): 0.64, D(G(z)): 0.36\n",
      "Epoch [7/100], Step [600/937], d_loss: 1.1783, g_loss: 1.4248, D(x): 0.58, D(G(z)): 0.37\n",
      "Epoch [7/100], Step [800/937], d_loss: 1.0253, g_loss: 1.2062, D(x): 0.62, D(G(z)): 0.36\n",
      "Epoch [8/100], Step [200/937], d_loss: 1.0826, g_loss: 1.2437, D(x): 0.65, D(G(z)): 0.39\n",
      "Epoch [8/100], Step [400/937], d_loss: 1.0930, g_loss: 1.0397, D(x): 0.63, D(G(z)): 0.34\n",
      "Epoch [8/100], Step [600/937], d_loss: 1.1319, g_loss: 1.0324, D(x): 0.59, D(G(z)): 0.39\n",
      "Epoch [8/100], Step [800/937], d_loss: 1.2789, g_loss: 1.0911, D(x): 0.56, D(G(z)): 0.41\n",
      "Epoch [9/100], Step [200/937], d_loss: 1.3852, g_loss: 0.9777, D(x): 0.54, D(G(z)): 0.42\n",
      "Epoch [9/100], Step [400/937], d_loss: 1.2003, g_loss: 1.4088, D(x): 0.60, D(G(z)): 0.38\n",
      "Epoch [9/100], Step [600/937], d_loss: 1.0860, g_loss: 1.1576, D(x): 0.65, D(G(z)): 0.38\n",
      "Epoch [9/100], Step [800/937], d_loss: 1.0901, g_loss: 1.3600, D(x): 0.59, D(G(z)): 0.37\n",
      "Epoch [10/100], Step [200/937], d_loss: 1.1416, g_loss: 1.1900, D(x): 0.54, D(G(z)): 0.33\n",
      "Epoch [10/100], Step [400/937], d_loss: 1.3510, g_loss: 1.0252, D(x): 0.53, D(G(z)): 0.34\n",
      "Epoch [10/100], Step [600/937], d_loss: 1.1649, g_loss: 1.1672, D(x): 0.58, D(G(z)): 0.38\n",
      "Epoch [10/100], Step [800/937], d_loss: 1.1552, g_loss: 1.5164, D(x): 0.56, D(G(z)): 0.34\n",
      "Epoch [11/100], Step [200/937], d_loss: 1.0623, g_loss: 1.1437, D(x): 0.58, D(G(z)): 0.31\n",
      "Epoch [11/100], Step [400/937], d_loss: 1.0714, g_loss: 1.0775, D(x): 0.57, D(G(z)): 0.34\n",
      "Epoch [11/100], Step [600/937], d_loss: 1.4150, g_loss: 1.0832, D(x): 0.51, D(G(z)): 0.39\n",
      "Epoch [11/100], Step [800/937], d_loss: 0.9684, g_loss: 1.0901, D(x): 0.65, D(G(z)): 0.34\n",
      "Epoch [12/100], Step [200/937], d_loss: 1.3246, g_loss: 1.1521, D(x): 0.57, D(G(z)): 0.44\n",
      "Epoch [12/100], Step [400/937], d_loss: 1.4104, g_loss: 1.4343, D(x): 0.55, D(G(z)): 0.43\n",
      "Epoch [12/100], Step [600/937], d_loss: 0.8188, g_loss: 1.4121, D(x): 0.67, D(G(z)): 0.29\n",
      "Epoch [12/100], Step [800/937], d_loss: 1.2231, g_loss: 1.0935, D(x): 0.57, D(G(z)): 0.40\n",
      "Epoch [13/100], Step [200/937], d_loss: 1.0163, g_loss: 1.3046, D(x): 0.64, D(G(z)): 0.37\n",
      "Epoch [13/100], Step [400/937], d_loss: 1.2190, g_loss: 0.9279, D(x): 0.62, D(G(z)): 0.46\n",
      "Epoch [13/100], Step [600/937], d_loss: 1.0754, g_loss: 1.3598, D(x): 0.55, D(G(z)): 0.29\n",
      "Epoch [13/100], Step [800/937], d_loss: 1.2927, g_loss: 0.9530, D(x): 0.62, D(G(z)): 0.47\n",
      "Epoch [14/100], Step [200/937], d_loss: 1.1920, g_loss: 0.8465, D(x): 0.58, D(G(z)): 0.43\n",
      "Epoch [14/100], Step [400/937], d_loss: 1.4481, g_loss: 0.8066, D(x): 0.55, D(G(z)): 0.43\n",
      "Epoch [14/100], Step [600/937], d_loss: 1.1537, g_loss: 1.1888, D(x): 0.56, D(G(z)): 0.36\n",
      "Epoch [14/100], Step [800/937], d_loss: 0.9644, g_loss: 1.0794, D(x): 0.63, D(G(z)): 0.35\n",
      "Epoch [15/100], Step [200/937], d_loss: 1.2083, g_loss: 0.9399, D(x): 0.56, D(G(z)): 0.40\n",
      "Epoch [15/100], Step [400/937], d_loss: 1.0503, g_loss: 1.3198, D(x): 0.65, D(G(z)): 0.39\n",
      "Epoch [15/100], Step [600/937], d_loss: 1.1943, g_loss: 1.1367, D(x): 0.56, D(G(z)): 0.35\n",
      "Epoch [15/100], Step [800/937], d_loss: 1.0586, g_loss: 0.9307, D(x): 0.61, D(G(z)): 0.39\n",
      "Epoch [16/100], Step [200/937], d_loss: 1.1027, g_loss: 1.2633, D(x): 0.59, D(G(z)): 0.35\n",
      "Epoch [16/100], Step [400/937], d_loss: 1.1527, g_loss: 1.0251, D(x): 0.59, D(G(z)): 0.39\n",
      "Epoch [16/100], Step [600/937], d_loss: 1.0687, g_loss: 1.3510, D(x): 0.63, D(G(z)): 0.38\n",
      "Epoch [16/100], Step [800/937], d_loss: 1.1488, g_loss: 1.0609, D(x): 0.57, D(G(z)): 0.37\n",
      "Epoch [17/100], Step [200/937], d_loss: 1.1001, g_loss: 1.0887, D(x): 0.62, D(G(z)): 0.38\n",
      "Epoch [17/100], Step [400/937], d_loss: 1.0353, g_loss: 1.0816, D(x): 0.63, D(G(z)): 0.36\n",
      "Epoch [17/100], Step [600/937], d_loss: 1.2039, g_loss: 0.9916, D(x): 0.60, D(G(z)): 0.44\n",
      "Epoch [17/100], Step [800/937], d_loss: 1.1775, g_loss: 0.8912, D(x): 0.64, D(G(z)): 0.42\n",
      "Epoch [18/100], Step [200/937], d_loss: 1.0652, g_loss: 1.2297, D(x): 0.63, D(G(z)): 0.38\n",
      "Epoch [18/100], Step [400/937], d_loss: 1.1230, g_loss: 1.1310, D(x): 0.61, D(G(z)): 0.34\n",
      "Epoch [18/100], Step [600/937], d_loss: 1.0138, g_loss: 1.1243, D(x): 0.60, D(G(z)): 0.34\n",
      "Epoch [18/100], Step [800/937], d_loss: 1.2995, g_loss: 0.8671, D(x): 0.53, D(G(z)): 0.42\n",
      "Epoch [19/100], Step [200/937], d_loss: 1.1583, g_loss: 1.1093, D(x): 0.60, D(G(z)): 0.40\n",
      "Epoch [19/100], Step [400/937], d_loss: 1.0729, g_loss: 1.3088, D(x): 0.63, D(G(z)): 0.35\n",
      "Epoch [19/100], Step [600/937], d_loss: 1.2480, g_loss: 1.2165, D(x): 0.58, D(G(z)): 0.43\n",
      "Epoch [19/100], Step [800/937], d_loss: 1.0309, g_loss: 1.0633, D(x): 0.67, D(G(z)): 0.40\n",
      "Epoch [20/100], Step [200/937], d_loss: 1.1313, g_loss: 0.9768, D(x): 0.63, D(G(z)): 0.41\n",
      "Epoch [20/100], Step [400/937], d_loss: 1.0699, g_loss: 1.0581, D(x): 0.63, D(G(z)): 0.39\n",
      "Epoch [20/100], Step [600/937], d_loss: 1.3748, g_loss: 1.0149, D(x): 0.59, D(G(z)): 0.47\n",
      "Epoch [20/100], Step [800/937], d_loss: 1.0997, g_loss: 1.2497, D(x): 0.63, D(G(z)): 0.37\n",
      "Epoch [21/100], Step [200/937], d_loss: 1.1542, g_loss: 1.0228, D(x): 0.64, D(G(z)): 0.43\n",
      "Epoch [21/100], Step [400/937], d_loss: 1.1284, g_loss: 0.9887, D(x): 0.67, D(G(z)): 0.43\n",
      "Epoch [21/100], Step [600/937], d_loss: 1.2389, g_loss: 1.2887, D(x): 0.58, D(G(z)): 0.40\n",
      "Epoch [21/100], Step [800/937], d_loss: 1.0862, g_loss: 1.0098, D(x): 0.61, D(G(z)): 0.40\n",
      "Epoch [22/100], Step [200/937], d_loss: 0.9651, g_loss: 1.4982, D(x): 0.63, D(G(z)): 0.32\n",
      "Epoch [22/100], Step [400/937], d_loss: 1.1942, g_loss: 1.0703, D(x): 0.61, D(G(z)): 0.43\n",
      "Epoch [22/100], Step [600/937], d_loss: 1.1910, g_loss: 0.8832, D(x): 0.58, D(G(z)): 0.40\n",
      "Epoch [22/100], Step [800/937], d_loss: 1.2562, g_loss: 1.0445, D(x): 0.60, D(G(z)): 0.43\n",
      "Epoch [23/100], Step [200/937], d_loss: 1.3549, g_loss: 0.9565, D(x): 0.53, D(G(z)): 0.40\n",
      "Epoch [23/100], Step [400/937], d_loss: 1.2560, g_loss: 1.0398, D(x): 0.57, D(G(z)): 0.44\n",
      "Epoch [23/100], Step [600/937], d_loss: 1.1648, g_loss: 0.9961, D(x): 0.59, D(G(z)): 0.40\n",
      "Epoch [23/100], Step [800/937], d_loss: 1.3209, g_loss: 0.9038, D(x): 0.53, D(G(z)): 0.43\n",
      "Epoch [24/100], Step [200/937], d_loss: 1.1276, g_loss: 0.9552, D(x): 0.62, D(G(z)): 0.42\n",
      "Epoch [24/100], Step [400/937], d_loss: 1.2138, g_loss: 1.0801, D(x): 0.61, D(G(z)): 0.46\n",
      "Epoch [24/100], Step [600/937], d_loss: 1.3726, g_loss: 0.8792, D(x): 0.56, D(G(z)): 0.47\n",
      "Epoch [24/100], Step [800/937], d_loss: 1.2335, g_loss: 1.0059, D(x): 0.56, D(G(z)): 0.38\n",
      "Epoch [25/100], Step [200/937], d_loss: 1.4845, g_loss: 1.0034, D(x): 0.50, D(G(z)): 0.43\n",
      "Epoch [25/100], Step [400/937], d_loss: 1.1693, g_loss: 1.0948, D(x): 0.56, D(G(z)): 0.35\n",
      "Epoch [25/100], Step [600/937], d_loss: 1.3118, g_loss: 1.0650, D(x): 0.53, D(G(z)): 0.40\n",
      "Epoch [25/100], Step [800/937], d_loss: 1.0221, g_loss: 1.0441, D(x): 0.67, D(G(z)): 0.41\n",
      "Epoch [26/100], Step [200/937], d_loss: 1.2650, g_loss: 0.8293, D(x): 0.54, D(G(z)): 0.42\n",
      "Epoch [26/100], Step [400/937], d_loss: 1.2530, g_loss: 0.8975, D(x): 0.59, D(G(z)): 0.44\n",
      "Epoch [26/100], Step [600/937], d_loss: 1.1228, g_loss: 1.0637, D(x): 0.60, D(G(z)): 0.40\n",
      "Epoch [26/100], Step [800/937], d_loss: 1.2063, g_loss: 0.8608, D(x): 0.59, D(G(z)): 0.43\n",
      "Epoch [27/100], Step [200/937], d_loss: 1.2768, g_loss: 0.9119, D(x): 0.59, D(G(z)): 0.44\n",
      "Epoch [27/100], Step [400/937], d_loss: 1.1531, g_loss: 1.1693, D(x): 0.58, D(G(z)): 0.34\n",
      "Epoch [27/100], Step [600/937], d_loss: 1.1348, g_loss: 0.8760, D(x): 0.58, D(G(z)): 0.38\n",
      "Epoch [27/100], Step [800/937], d_loss: 1.4093, g_loss: 1.1149, D(x): 0.48, D(G(z)): 0.38\n",
      "Epoch [28/100], Step [200/937], d_loss: 1.2100, g_loss: 0.7965, D(x): 0.59, D(G(z)): 0.43\n",
      "Epoch [28/100], Step [400/937], d_loss: 1.1591, g_loss: 1.1319, D(x): 0.61, D(G(z)): 0.38\n",
      "Epoch [28/100], Step [600/937], d_loss: 1.3016, g_loss: 0.8820, D(x): 0.60, D(G(z)): 0.49\n",
      "Epoch [28/100], Step [800/937], d_loss: 1.3147, g_loss: 0.9711, D(x): 0.59, D(G(z)): 0.48\n",
      "Epoch [29/100], Step [200/937], d_loss: 1.1333, g_loss: 1.1208, D(x): 0.60, D(G(z)): 0.38\n",
      "Epoch [29/100], Step [400/937], d_loss: 1.1302, g_loss: 1.1784, D(x): 0.63, D(G(z)): 0.41\n",
      "Epoch [29/100], Step [600/937], d_loss: 1.1279, g_loss: 0.8838, D(x): 0.61, D(G(z)): 0.41\n",
      "Epoch [29/100], Step [800/937], d_loss: 1.2297, g_loss: 1.0435, D(x): 0.61, D(G(z)): 0.45\n",
      "Epoch [30/100], Step [200/937], d_loss: 1.1746, g_loss: 1.1105, D(x): 0.57, D(G(z)): 0.38\n",
      "Epoch [30/100], Step [400/937], d_loss: 1.1244, g_loss: 1.0237, D(x): 0.60, D(G(z)): 0.35\n",
      "Epoch [30/100], Step [600/937], d_loss: 1.1714, g_loss: 0.8861, D(x): 0.63, D(G(z)): 0.45\n",
      "Epoch [30/100], Step [800/937], d_loss: 1.2569, g_loss: 0.7693, D(x): 0.61, D(G(z)): 0.46\n",
      "Epoch [31/100], Step [200/937], d_loss: 1.2540, g_loss: 0.9919, D(x): 0.54, D(G(z)): 0.39\n",
      "Epoch [31/100], Step [400/937], d_loss: 1.1576, g_loss: 0.8559, D(x): 0.65, D(G(z)): 0.45\n",
      "Epoch [31/100], Step [600/937], d_loss: 1.1104, g_loss: 0.9430, D(x): 0.62, D(G(z)): 0.41\n",
      "Epoch [31/100], Step [800/937], d_loss: 1.2004, g_loss: 1.1456, D(x): 0.54, D(G(z)): 0.38\n",
      "Epoch [32/100], Step [200/937], d_loss: 1.1894, g_loss: 1.0114, D(x): 0.60, D(G(z)): 0.44\n",
      "Epoch [32/100], Step [400/937], d_loss: 1.1292, g_loss: 0.9010, D(x): 0.61, D(G(z)): 0.42\n",
      "Epoch [32/100], Step [600/937], d_loss: 1.3770, g_loss: 1.0392, D(x): 0.51, D(G(z)): 0.43\n",
      "Epoch [32/100], Step [800/937], d_loss: 1.1693, g_loss: 1.2041, D(x): 0.55, D(G(z)): 0.36\n",
      "Epoch [33/100], Step [200/937], d_loss: 1.2006, g_loss: 1.1787, D(x): 0.59, D(G(z)): 0.40\n",
      "Epoch [33/100], Step [400/937], d_loss: 1.2906, g_loss: 0.9094, D(x): 0.57, D(G(z)): 0.47\n",
      "Epoch [33/100], Step [600/937], d_loss: 1.1523, g_loss: 1.1830, D(x): 0.60, D(G(z)): 0.40\n",
      "Epoch [33/100], Step [800/937], d_loss: 1.3126, g_loss: 0.8052, D(x): 0.56, D(G(z)): 0.47\n",
      "Epoch [34/100], Step [200/937], d_loss: 1.3146, g_loss: 0.7992, D(x): 0.59, D(G(z)): 0.49\n",
      "Epoch [34/100], Step [400/937], d_loss: 1.1653, g_loss: 1.0577, D(x): 0.56, D(G(z)): 0.37\n",
      "Epoch [34/100], Step [600/937], d_loss: 1.2860, g_loss: 0.7816, D(x): 0.58, D(G(z)): 0.46\n",
      "Epoch [34/100], Step [800/937], d_loss: 1.1024, g_loss: 0.9713, D(x): 0.61, D(G(z)): 0.41\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m g_losses \u001b[39m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mfor\u001b[39;00m i, (images, real_labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainloader):\n\u001b[1;32m      8\u001b[0m         \u001b[39m#train the discriminator on real images\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mreshape(batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m         real_labels \u001b[39m=\u001b[39m real_labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 624\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49mrecord_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_profile_name):\n\u001b[1;32m    625\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m             \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/autograd/profiler.py:485\u001b[0m, in \u001b[0;36mrecord_function.__init__\u001b[0;34m(self, name, args)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks_on_exit: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[39m# Stores underlying RecordFunction as a tensor. TODO: move to custom\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39m# class (https://github.com/pytorch/pytorch/issues/35026).\u001b[39;00m\n\u001b[0;32m--> 485\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training\n",
    "num_epochs = 100\n",
    "total_step = len(trainloader)\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, real_labels) in enumerate(trainloader):\n",
    "        #train the discriminator on real images\n",
    "        images = images.reshape(batch_size, -1).to(device)\n",
    "        real_labels = real_labels.to(device)\n",
    "        real_labels_one_hot = get_one_hot_labels(real_labels, n_classes).to(device)\n",
    "        real_outputs = discriminator(images, real_labels_one_hot).view(-1)\n",
    "        d_loss_real = criterion(real_outputs, torch.ones_like(real_outputs))\n",
    "        real_score = real_outputs\n",
    "        #train the discriminator on fake images\n",
    "        z = torch.randn(batch_size, 100).to(device)\n",
    "        fake_labels = torch.randint(0, n_classes, (batch_size,)).to(device)\n",
    "        fake_labels_one_hot = get_one_hot_labels(fake_labels, n_classes).to(device)\n",
    "        fake_images = generator(z, fake_labels_one_hot)\n",
    "        fake_outputs = discriminator(fake_images, fake_labels_one_hot).view(-1)\n",
    "        d_loss_fake = criterion(fake_outputs, torch.zeros_like(fake_outputs))\n",
    "        fake_score = fake_outputs\n",
    "        #backprop and optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        #train the generator\n",
    "        z = torch.randn(batch_size, 100).to(device)\n",
    "        fake_labels = torch.randint(0, n_classes, (batch_size,)).to(device)\n",
    "        fake_labels_one_hot = get_one_hot_labels(fake_labels, n_classes).to(device)\n",
    "        fake_images = generator(z, fake_labels_one_hot)\n",
    "        outputs = discriminator(fake_images, fake_labels_one_hot).view(-1)\n",
    "        g_loss = criterion(outputs, torch.ones_like(outputs))\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'\n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(),\n",
    "                          real_score.mean().item(), fake_score.mean().item()))\n",
    "    d_losses.append(d_loss.item())\n",
    "    g_losses.append(g_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate images\n",
    "z = torch.randn(batch_size, 100).to(device)\n",
    "fake_labels = torch.randint(9, 10, (batch_size,)).to(device)\n",
    "fake_labels_one_hot = get_one_hot_labels(fake_labels, n_classes).to(device)\n",
    "fake_images = generator(z, fake_labels_one_hot)\n",
    "fake_images = fake_images.reshape(batch_size, 1, 28, 28)\n",
    "fake_images = fake_images.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3x3 grid of images\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, sharex=True, sharey=True, figsize=(5,5))\n",
    "for ax, img in zip(axes.flatten(), fake_images):\n",
    "    img = img.numpy()\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77f0ac4a1ff910c6f832be6ab53afe92115f75471ff7ffff1273b50351d0e386"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
